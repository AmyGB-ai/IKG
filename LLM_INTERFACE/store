ooooooooooooooooooooooooooooooooooooooooooo
---------------------------------
CHUNK-> import json, math, sys, traceback, copy, multiprocessing, os
from dateutil import parser
import numpy as np
import openpyxl
from openpyxl.utils import column_index_from_string
import time, random, datetime
import pandas as pd
from sklearn.decomposition import PCA

import query_llama3_via_groq as llama3
import query_gpt_via_groq as openai
import createJsonFeats
import db_utils

def is_date( input_str):
        ## first check for INT and FLOAT since parser foolishly accepts ints
        try:
            _ = int( input_str )
            return None
        except:
            pass

        try:
            _ = float( input_str )
            return None
        except:
            pass

        try:
            return parser.parse(input_str)
        except ValueError:
            return None

def process( colNum, sheet, tbl ):
        dt_counts_ = []

        for rw in range( tbl['START_ROW'], tbl['END_ROW'] ):
                dtVal_ = is_date( str( sheet.cell(row=rw, column=colNum).value ) )

                if dtVal_ is not None : 
                    dt_counts_.append( dtVal_ ) 

        if len( dt_counts_ ) >= ( tbl['END_ROW'] - tbl['START_ROW'] )/2: 
                ## defensive chk to ensure dt counts are high
                print('Dt Col found !', colNum)
                ## sort the values to get range
                sorted_dates_ = sorted( dt_counts_ )
                print('Dt range->', sorted_dates_[0], sorted_dates_[-1] )

                return ( True, sorted_dates_[0].strftime('%B %d, %Y'), sorted_dates_[-1].strftime('%B %d, %Y') )

        return ( False, None, None )

class GenerateXLMetaInfo:
    def __init__(self, file_path, llm='LLAMA'):
        """
        Initialize the GenerateXmlMetaInfo class with the XML file.

        Parameters:
        - xml_file (str): The path to the XML file.
        """
        self.file_path = file_path
        self.masterInfo_ = dict()
        self.llm_framework_ = llm
        self.sheet = None
        self.sklearn_pca_object_ = PCA()

MODULE_VARIABLES-> ["json", "math", "sys", "traceback", "copy", "multiprocessing", "os", "parser", "np", "openpyxl", "column_index_from_string", "time", "random", "datetime", "pd", "PCA", "llama3", "openai", "createJsonFeats", "db_utils"]
PACKAGE_VARIABLES-> [ 
  { "numpy": "np" }, 
  { "pandas": "pd" }, 
  { "query_llama3_via_groq": "llama3" }, 
  { "query_gpt_via_groq": "openai" }, 
  { "sklearn.decomposition": "PCA" }
]
METHODS-> [ 
    { 'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None' },
    { 'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )' },
    { 'method_name': '__init__', 'method_begin': 'def __init__(self, file_path, llm=\'LLAMA\'): ', 'method_end': 'self.sklearn_pca_object_ = PCA()' }
]
time post groq-> 2.402341365814209
ENTERING-> processModuleVars  ["json", "math", "sys", "traceback", "copy", "multiprocessing", "os", "parser", "np", "openpyxl", "column_index_from_string", "time", "random", "datetime", "pd", "PCA", "llama3", "openai", "createJsonFeats", "db_utils"]
First occurence of  json  line # 0
First occurence of  math  line # 0
First occurence of  sys  line # 0
First occurence of  traceback  line # 0
First occurence of  copy  line # 0
First occurence of  multiprocessing  line # 0
First occurence of  os  line # 0
First occurence of  parser  line # 1
First occurence of  np  line # 2
First occurence of  openpyxl  line # 3
First occurence of  column_index_from_string  line # 4
First occurence of  time  line # 5
First occurence of  random  line # 5
First occurence of  datetime  line # 5
First occurence of  pd  line # 6
First occurence of  PCA  line # 7
First occurence of  llama3  line # 9
First occurence of  openai  line # 10
First occurence of  createJsonFeats  line # 11
First occurence of  db_utils  line # 12
First occurence of  numpy  line # 2
First occurence of  pandas  line # 6
First occurence of  query_llama3_via_groq  line # 9
First occurence of  query_gpt_via_groq  line # 10
First occurence of  sklearn.decomposition  line # 7
EXISTING file_methods_ =  [] [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None'}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )'}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()'}]
First occurence of  def is_date( input_str):  line # 14
First occurence of  return None  line # 18
First occurence of  def process( colNum, sheet, tbl ):  line # 33
First occurence of  return ( False, None, None )  line # 51
First occurence of  def __init__(self, file_path, llm='LLAMA'):   line # 54
First occurence of  self.sklearn_pca_object_ = PCA()  line # 65
CHUNK_ENDS-> backtrack_ =  False
time post pprocess-> 2.406834602355957
---------------------------------
CHUNK->         self.add_ai_summary_to_embedding_ = True
        self.chunk_size_ = 500 ## approx 1024 tokens

        self.sz_of_phrase_, self.unique_str_thresh_, self.number_str_thresh_ = 5, 0.5, 0.4
        self.pca_var_min_contrib, self.feature_contribution_per_thresh_ = 0.5, 0.3
        self.max_tables_per_sheet_ = 10 ## at times a single sheet can have multiple tables
        self.num_rows_to_consider_, self.col_thresh_, self.minElemsInTable, self.max_rows_variance = 4, 0.8, 6, 100
        self.default_max_col_ , self.default_max_row_, self.max_cols_for_review_, \
                self.min_num_distinct_values_, self.max_elements_for_summary_ = 50, 50, 10, 3, 15

        if llm == 'OPENAI':
            self.query_fn_ = openai
        else:
            ## default , llama3 inferred via groq
            self.query_fn_ = llama3
   
    def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):

        # Iterate over rows to find the start and end rows
        start_row_idx_ = 1 if start_row is None else start_row
        start_col_idx_ = 1 if start_col is None else start_col
        
        ## need to add 2 to max rw and col since max_row of sheet returns the last row with data
        ## and range will stop at max_row - 1 
        for row in range( start_row_idx_ , max_row + 2):
            if all( self.sheet.cell(row=row, column=col).value is None for col in range(1, max_col + 2)):
                if start_row is None:
                    continue  # Skip empty rows before the table
                else:
                    end_row = row - 1
                    break
            elif start_row is None:
                start_row = row
           
        # Iterate over columns to find the start and end columns
        for col in range( start_col_idx_, max_col + 2):
            #for row in range(start_row, end_row):
            #    print('ROW NUM->', col, ' VALUE: ', sheet.cell(row=row, column=col).value )
            if end_row is None: continue


MODULE_VARIABLES-> "NA"
PACKAGE_VARIABLES-> NA
METHODS-> [ 
{ 'method_name': 'find_bounds' , 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA' } 
]
time post groq-> 7.103238105773926
ENTERING-> processModuleVars  "NA"
First occurence of  N  line # 15
First occurence of  A  line # 7
No array returned by the model
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}] [{'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA'}]
First occurence of  def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):  line # 82
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 7.1047141551971436
---------------------------------
CHUNK->             if all( self.sheet.cell(row=row, column=col).value is None for row in range(start_row, end_row)):
                if start_col is None:
                    continue  # Skip empty columns before the table
                else:
                    end_col = col - 1
                    break
            elif start_col is None:
                start_col = col
            

        #print('Found tables between-> start_row, end_row, start_col, end_col = ',\
        #        start_row, end_row, start_col, end_col )

        return start_row, end_row, start_col, end_col

    def is_hdr_row_format( self, tbl_bound, sheet ):
        
        num_str_cols_ = 0
        for col_ctr in range( tbl_bound['START_COL'], tbl_bound['END_COL'] ):
            if type( self.sheet.cell(row=tbl_bound['START_ROW'], column=col_ctr).value ) == str:
                num_str_cols_ += 1

        if num_str_cols_ < ( tbl_bound['END_COL'] - tbl_bound['START_COL'] ): return False

        return True

    def find_tables(self, sheet):
        ## NOTE -> sheet.max_row and sheet.max_column is NOT WORKING !! NEED TO FIX
        ## default is stop gap
        max_row = sheet.max_row if sheet.max_row is not None else self.default_max_row_
        max_col = sheet.max_column if sheet.max_column is not None else self.default_max_col_
        table_bounds_ = []

        print('KKR->', max_row, max_col)
        timer_ = time.time()
        # Initialize variables to track the bounds
        start_row ,end_row ,start_col ,end_col = None, None, 1, sheet.max_column

        ## do a first pass to find the first table
        start_row, end_row, start_col, end_col = self.find_bounds( sheet, max_row, max_col, start_row ,\
                                                                         end_row ,start_col ,end_col )

        print('Time taken->', time.time() - timer_, start_row, end_row, start_col, end_col)    
        init_end_col = copy.copy( end_col )

        table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\

MODULE_VARIABLES-> ["default_max_row_", "default_max_col_"]
PACKAGE_VARIABLES-> [{'openpyxl', 'None'}, {'copy', 'copy'}, {'time', 'time'}]
METHODS-> [ 
    { "method_name": "find_bounds", "method_begin": "def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ", "method_end": "return start_row, end_row, start_col, end_col" },
    { "method_name": "is_hdr_row_format", "method_begin": "def is_hdr_row_format( self, tbl_bound, sheet ): ", "method_end": "return True" },
    { "method_name": "find_tables", "method_begin": "def find_tables(self, sheet): ", "method_end": "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ " }
]
time post groq-> 12.083765506744385
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}] [{'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col'}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True'}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ "}]
First occurence of  def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ):   line # 82
First occurence of  return start_row, end_row, start_col, end_col  line # 119
First occurence of  def is_hdr_row_format( self, tbl_bound, sheet ):   line # 121
First occurence of  return True  line # 130
First occurence of  def find_tables(self, sheet):   line # 132
First occurence of  table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\   line # 151
CHUNK_ENDS-> backtrack_ =  False
time post pprocess-> 12.08717656135559
---------------------------------
CHUNK->                                     'START_COL': start_col, 'END_COL': end_col } ) 

        ## now iterate from end_row to max_row to find all tables row wise
        while end_row is not None:
            end_row += 2 ## increment by 2 since we need to look ahead and see if any more tables exist !
            ##              if u increment by 1 then u will end up on the same blank line that stopped the prev tbl  
            ## start_row is assigned the value of end_row from above and end_row is made None
            if end_row >= max_row: break

            #print('DUM ROW->', end_row)
            start_row, end_row, start_col, end_col = self.find_bounds( sheet, max_row, max_col, end_row ,\
                                                                             None , None , None )

            if ( start_col is None or end_col is None ) or \
                    ( abs( start_row - end_row )*abs( start_col - end_col ) ) <= self.minElemsInTable: continue    

            table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\
                                    'START_COL': start_col, 'END_COL': end_col } ) 
        
        ## now iterate from end_col to max_col to find all tables cols wise
        while init_end_col is not None:
            init_end_col += 2 ## increment by 1 since we need to look ahead and see if any more tables exist !
            ## start_row is assigned the value of end_row from above and end_row is made None
            if init_end_col >= max_col: break

            #print('DUM COL->', init_end_col)
            start_row, end_row, start_col, end_col = self.find_bounds( sheet, max_row, max_col, None ,\
                                                                             None , init_end_col , None )

            if ( start_col >= end_col ): continue    

            table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\
                                    'START_COL': start_col, 'END_COL': end_col } ) 

        ## init star and end col to min and max

MODULE_VARIABLES-> ["minElemsInTable"]
PACKAGE_VARIABLES-> NA
METHODS-> [ 
  { 'method_name': 'find_bounds', 'method_begin': 'def find_bounds(self, sheet, max_row, max_col, end_row, None, None, None):', 'method_end': 'NA' } 
]
time post groq-> 16.642751693725586
ENTERING-> processModuleVars  ["minElemsInTable"]
First occurence of  minElemsInTable  line # 72
No array returned by the model
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}] [{'method_name': 'find_bounds', 'method_begin': 'def find_bounds(self, sheet, max_row, max_col, end_row, None, None, None):', 'method_end': 'NA'}]
First occurence of  NA  line # 76
CHUNK_ENDS-> backtrack_ =  False
time post pprocess-> 16.645838260650635
---------------------------------
CHUNK->         for tab in table_bounds_: tab['START_COL'] = 1; tab['END_COL'] = max_col;
        ## remove dupes
        tmp_, dupe = [], set()

        for idx1, tab1 in enumerate( table_bounds_ ):
            for idx2, tab2 in enumerate( table_bounds_ ):
                if idx1 <= idx2: continue
                if tab2['START_ROW'] >= tab1['START_ROW'] and tab2['END_ROW'] <= tab1['END_ROW']:
                    dupe.add( idx2 )

        for idx, tab in enumerate( table_bounds_ ):
            if idx not in list( dupe ):
                tmp_.append( tab )

        ## blend tables - in case the rows are FPs
        final_resp_ = []
        if len( tmp_ ) > 1:
            last_tbl_ = tmp_[0]
            final_resp_.append( last_tbl_ )
            ## check if the first row is not all STR
            for ctr in range( 1, len( tmp_ ) ):
                if self.is_hdr_row_format( tmp_[ctr], sheet ) == False:
                    ## blend with the last table
                    final_resp_[-1]['END_ROW'] = tmp_[ctr]['END_ROW']
                else:
                    final_resp_.append( table_bounds_ )
        else:
            final_resp_ = tmp_

        return final_resp_[ : min( self.max_tables_per_sheet_, len( final_resp_ ) ) ]

    def findDateRange( self, tbl ):

        colRange_ = list( range( tbl['START_COL'], tbl['END_COL'] ) )

        for col in colRange_:
            ## process was taken out of the class only because multi processing map refused to pickle
            ## a method that was part of the class ..and it proved way slower ..so parallels been removed..lol
            results = process(col, self.sheet, tbl)
            if results[0] is True:
                    return str( results[1] ) +' To '+ str( results[2] )

        return (None, None)

    def findHeaderInfo(self, tbl):
        """
        Find header information from the XL file.
        take the first 2 rows and then to be on the safe side also take the 

MODULE_VARIABLES-> ["max_tables_per_sheet_"]
PACKAGE_VARIABLES-> [ ]
METHODS-> [ 
  { 'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)' }, 
  { 'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA' } 
]
time post groq-> 52.75460481643677
ENTERING-> processModuleVars  ["max_tables_per_sheet_"]
First occurence of  max_tables_per_sheet_  line # 71
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}] [{'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)'}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA'}]
First occurence of  def findDateRange( self, tbl ):  line # 218
First occurence of  return (None, None)  line # 229
First occurence of  def findHeaderInfo(self, tbl):  line # 231
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 52.75809836387634
---------------------------------
CHUNK->         first 2 columns ( in case the col headers are just numbers / % etc and the row contain item name in the first col )
        send it to the LLM for a summary
        ALSO there's no need to take all ROWS and COLS .. some 10-15 elements are more than enough but can be adjustedfor domains that need more
        """

        hdr_row_start_ = self.findHdrRow( tbl )
        row_starter_ = tbl['START_ROW'] if hdr_row_start_ is None else hdr_row_start_

        col_frame_ = ''

        for rw in range( row_starter_ , min( row_starter_ + self.num_rows_to_consider_, tbl['END_ROW'] ) ):
            for col in range( tbl['START_COL'], min( self.max_elements_for_summary_, tbl['END_COL'] + 1 ) ):
                col_frame_ += '\t' + str( self.sheet.cell(row=rw, column=col).value )

            col_frame_ += '\n'

        return col_frame_

    def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):
        '''
        iterate through columns that have numeric values and figure out the more important columns
        num of rows - we can restrict it to lets say 1k rows ..should suffice 
        '''
        numeric_frame_, high_var_indices_, hdr_col_names_ = dict(), set(), []
        end_row_ =  min( tbl['START_ROW'] + self.max_rows_variance , tbl['END_ROW'] + 1 )
        ## add 1 to the start row since we dont want to include the header value
        start_row_ = ( tbl['START_ROW'] if start_hdr_row_ is None else start_hdr_row_ ) + 1 
        
        print('BIGGIE-> start_row_, end_row_ = ', start_row_, end_row_)

        for col_ctr in range( tbl['START_COL'], tbl['END_COL']+1 ):
                hdr_col_names_.append( str( self.sheet.cell(row=start_row_-1, column=col_ctr).value ) )

        try:
            for col_ctr in range( tbl['START_COL'], tbl['END_COL']+1 ):
                col_arr_ = [ 'NA' for x in range( ( end_row_ - start_row_ ) + 1 ) ]

                for idx, row_ctr in enumerate( range( start_row_, end_row_ ) ):

MODULE_VARIABLES-> ["num_rows_to_consider_", "max_elements_for_summary_", "max_rows_variance", "sheet"]
PACKAGE_VARIABLES-> NA
METHODS-> [ 
    { 'method_name': ' anonymoous function', 'method_begin': 'header summary', 'method_end': 'return col_frame_' },
    { 'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA' }
]
time post groq-> 91.98126912117004
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}] [{'method_name': ' anonymoous function', 'method_begin': 'header summary', 'method_end': 'return col_frame_'}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA'}]
First occurence of  return col_frame_  line # 251
First occurence of  def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):  line # 253
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 91.98529100418091
---------------------------------
CHUNK->                     col_arr_[ idx ] = str( self.sheet.cell(row=row_ctr, column=col_ctr).value )

                ## standardize the column since PCA better be done on std values
                col_set_ = set( col_arr_ )
                ## convert the variables into unique IDs
                uid = [ list( col_set_ ).index( x ) for x in col_arr_ ]
                max_uid_ = np.max( uid )
                ## normalize the int values
                numeric_frame_[ col_ctr ] = [ x/max_uid_ for x in uid ]

            if len( numeric_frame_.keys() ) > 0:
                ## now transpose the contents of the frame since we want it to retain the shape of a column
                transposed_ = np.transpose( np.asarray( list( numeric_frame_.values() ) ) )
                #print('The val of transposed_->', transposed_)
                ## perform PCA and pick the most high variance columns
                ## the number of components to be picked will be decided by the thresh self.percent_pca_var_
                self.sklearn_pca_object_.fit( transposed_ )
                ## components_loading_ will give you principal component wise contribution of the features
                components_loading_ = self.sklearn_pca_object_.components_
                ## only consider those components that contribute to 90% or whatever threshold level of variance
                relevant_loading_ = components_loading_[0] \
                                    if self.sklearn_pca_object_.explained_variance_ratio_[0] > self.pca_var_min_contrib \
                                    else []

                #print('LOADING AND REL_LOADING->', components_loading_, relevant_loading_)
                key_list_ = list( numeric_frame_.keys() )

                for feat_idx, feat_contribution in enumerate( relevant_loading_ ):
                        if feat_contribution >= self.feature_contribution_per_thresh_: 

                            high_var_indices_.add( hdr_col_names_[ key_list_[ feat_idx ] ] )


MODULE_VARIABLES-> ["self.percent_pca_var_", "self.pca_var_min_contrib", "self.feature_contribution_per_thresh_"]
PACKAGE_VARIABLES-> [ { 'numpy': 'np' }, { 'sklearn': None } ]
METHODS-> Here is the output:

[ ]
time post groq-> 130.2474880218506
No array returned by the model
CHUNK_ENDS-> backtrack_ =  None
time post pprocess-> 130.24753665924072
---------------------------------
CHUNK->                             #print('Adding ', hdr_col_names_[ key_list_[ feat_idx ] ],' As a high variance col')
        except:
            pass

        return list( high_var_indices_ ), hdr_col_names_


    def returnSummary(self, tbl ):
        '''
        take the first few rows to try and generate a coherent summary for the type of the data present
        i am also considering transposing the first few rows to see how different the summary looks
        ALSO maybe limiting the number of columns makes sense
        '''
        frame_, transposed_frame_, start_hdr_row_ = '', '', self.findHdrRow( tbl )
        
        time_ = time.time()
        high_variance_cols_, hdr_col_names_ = self.findHighVarianceColumns( start_hdr_row_, self.sheet, tbl )
        print('Time taken to find high var cols ->', time.time() - time_)
        print('AND THEY ARE->', high_variance_cols_)

        frame_num_contours_, transposed_frame_contours_ = 0, 0
        ## NATURAL order -> left to right, top to bottom
        for row_ctr in range( tbl['START_ROW'] if start_hdr_row_ is None else start_hdr_row_\
                              , min( tbl['START_ROW']+self.num_rows_to_consider_ , tbl['END_ROW']+1 ) ):

            for col_ctr in range( tbl['START_COL'], min( self.max_elements_for_summary_, tbl['END_COL']+1 ) ):

                frame_ += '\t' + str( self.sheet.cell(row=row_ctr, column=col_ctr).value )
                frame_num_contours_ += 1

            frame_ += '\n'

        return frame_, high_variance_cols_, list( set(hdr_col_names_) )

    def findHdrRow( self, tbl ):

        total_cols_ = tbl['END_COL'] - tbl['START_COL']

        for row_ctr in range( tbl['START_ROW'], \
                              min( tbl['START_ROW']+self.num_rows_to_consider_ , tbl['END_ROW']+1 ) ):
            num_non_blank_ = 0
            
            for col_ctr in range( tbl['START_COL'], tbl['END_COL'] ):
                if self.sheet.cell(row=row_ctr, column=col_ctr).value is not None and \

MODULE_VARIABLES-> ["num_rows_to_consider_", "max_elements_for_summary_"]
PACKAGE_VARIABLES-> [ { 'time': 'time_' } ]
METHODS-> [ 
  { "method_name": "returnSummary", "method_begin": "def returnSummary(self, tbl ): ", "method_end": "return frame_, high_variance_cols_, list( set(hdr_col_names_) )" }, 
  { "method_name": "findHdrRow", "method_begin": "def findHdrRow( self, tbl ): ", "method_end": "NA" } 
]
time post groq-> 165.91349530220032
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}] [{'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self, tbl ): ', 'method_end': 'return frame_, high_variance_cols_, list( set(hdr_col_names_) )'}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA'}]
First occurence of  def returnSummary(self, tbl ):   line # 312
First occurence of  return frame_, high_variance_cols_, list( set(hdr_col_names_) )  line # 337
First occurence of  def findHdrRow( self, tbl ):   line # 339
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 165.91806507110596
---------------------------------
CHUNK->                         len( str( self.sheet.cell(row=row_ctr, column=col_ctr).value ) ) > 0: 
                    num_non_blank_ += 1

            ## only if the number of hdr columns is in the ballpark w.r.t. total number of columns
            ## should we start the table ..at times the header table is split across more than 1 row
            if total_cols_ > 1 and (num_non_blank_/total_cols_) > self.col_thresh_:
                return row_ctr

        return None # so default value of row #1 applies to table start
    
    def createDBRec( self, summary_D, mode='NORM' ):

        insertRec = dict()
        insertRec['docID'] = random.randint( 1000, 100000 )
        ## combine all necessary fields to form vector signature
        ## keys-> 'sample_summary'; 'date_range' ; 'hdr_info'

        hdr_info = summary_D['hdr_info']
        sample_summary_ = summary_D['sample_summary']

        unified_key_ =   'Date Range : '+ str( summary_D['date_range'] ) + '\n' \
                       + 'Column Headers : '+ ' , '.join( summary_D['col_names_'] ).strip() + '\n' \
                       + 'LLM Summary : '+ ( sample_summary_ ) if self.add_ai_summary_to_embedding_ is True else ''

        emb_ = createJsonFeats.returnEmbed( unified_key_ )
        insertRec['docSignature'] = emb_
        insertRec['summary'] = unified_key_
        insertRec['file_path'] = summary_D['file_path']
        insertRec['file_name'] = summary_D['file_path'].split('/')[-1]
        insertRec['sheet_name'] = summary_D['sheet_name']
        insertRec['date_range'] = summary_D['date_range']
        insertRec['hdr_info'] = hdr_info

        print('Inserting RECORD->', insertRec['file_name'], insertRec['sheet_name'], unified_key_ )
        return insertRec

    def mergeAndInsert( self, summary_D ):
        '''
        we shall be inserting 2 records for every table
        a) the normal table structure
        b) the transposed table structure
        along with all meta info
        '''
        ##NORM TBL STRUCT

MODULE_VARIABLES-> ["add_ai_summary_to_embedding_", "col_thresh_"]
PACKAGE_VARIABLES-> [{ "random": "random" }]
METHODS-> [ 
{ 'method_name': '_method', 'method_begin': 'def _(self, row_ctr, col_ctr):', 'method_end': 'return None' }, 
{ 'method_name': 'createDBRec', 'method_begin': 'def createDBRec( self, summary_D, mode=\'NORM\' ):', 'method_end': 'return insertRec' }, 
{ 'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA' } ]
time post groq-> 206.36087560653687
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self, tbl ): ', 'method_end': 'return frame_, high_variance_cols_, list( set(hdr_col_names_) )', 'range': (312, 337)}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 76)}] [{'method_name': '_method', 'method_begin': 'def _(self, row_ctr, col_ctr):', 'method_end': 'return None'}, {'method_name': 'createDBRec', 'method_begin': "def createDBRec( self, summary_D, mode='NORM' ):", 'method_end': 'return insertRec'}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA'}]
First occurence of  return None  line # 18
First occurence of  def createDBRec( self, summary_D, mode='NORM' ):  line # 359
First occurence of  return insertRec  line # 383
First occurence of  def mergeAndInsert( self, summary_D ):  line # 385
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA', 'range': (385, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 206.36674237251282
---------------------------------
CHUNK->         rec_ = self.createDBRec( summary_D, 'NORM' )
        db_utils.insertNewSignature( rec_ )

    def returnEntireSheet( self, tbl_, sheet_name ):
        '''
        find if the entire sheet contains mostly textual information. If so, then we should simply
        chunk the whole sheet , after concatenating 
        A simple rule of thumb can be the length of the cell contents in any column.
        If the lenght of the cell contents is greater than some threshold say 10 words
        '''
        use_entire_sheet_, chunks_ = False, []

        for col_ctr in range( tbl_['START_COL'], tbl_['END_COL'] ):
            num_str_, unique_, ignore = 0, set(), False
            for row_ctr in range( tbl_['START_ROW'], tbl_['END_ROW'] ):
                if type( self.sheet.cell(row=row_ctr, column=col_ctr).value ) == str and\
                        len( (self.sheet.cell(row=row_ctr, column=col_ctr).value).split() ) >= self.sz_of_phrase_:
                            num_str_ += 1
                unique_.add( ( self.sheet.cell(row=row_ctr, column=col_ctr).value ) )

            ## if num of unique strings in col is low it means, this value is being repeated
            ## HENCE its mostly observations being selected from a drop down and does NOT need
            ## the entire doc chunked
            if len( unique_ ) < self.unique_str_thresh_*( tbl_['END_ROW'] - tbl_['START_ROW'] ): ignore = True
            
            print('returnEntireSheet->', sheet_name, tbl_, num_str_, ( tbl_['END_ROW'] - tbl_['START_ROW'] ), ignore)
            if num_str_ >= self.number_str_thresh_*( tbl_['END_ROW'] - tbl_['START_ROW'] ) and ignore is False:

                use_entire_sheet_ = True
                ## aggregate all text and chunk using self.chunk_size_
                frame_ = ''
                for row_ctr in range( tbl_['START_ROW'], tbl_['END_ROW'] ):
                    for col_ctr in range( tbl_['START_COL'], tbl_['END_COL'] ):
                        
                        if len( frame_ ) >= self.chunk_size_:

MODULE_VARIABLES-> ['sz_of_phrase_', 'unique_str_thresh_', 'number_str_thresh_', 'chunk_size_']
PACKAGE_VARIABLES-> NA
METHODS-> [ { "method_name": "returnEntireSheet" , "method_begin": "def returnEntireSheet( self, tbl_, sheet_name ): ", "method_end": "NA" } ]
time post groq-> 245.0292751789093
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self, tbl ): ', 'method_end': 'return frame_, high_variance_cols_, list( set(hdr_col_names_) )', 'range': (312, 337)}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 76)}, {'method_name': 'createDBRec', 'method_begin': "def createDBRec( self, summary_D, mode='NORM' ):", 'method_end': 'return insertRec', 'range': (359, 383)}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA', 'range': (385, 76)}] [{'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet( self, tbl_, sheet_name ): ', 'method_end': 'NA'}]
First occurence of  def returnEntireSheet( self, tbl_, sheet_name ):   line # 396
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet( self, tbl_, sheet_name ): ', 'method_end': 'NA', 'range': (396, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 245.03129386901855
---------------------------------
CHUNK->                             chunks_.append( frame_ )
                            frame_ = ''

                        frame_ += '\t'+ str( self.sheet.cell(row=row_ctr, column=col_ctr).value )
                    frame_ += '\n'

                if len( frame_ ) > 0: chunks_.append( frame_ )

        return chunks_, use_entire_sheet_

    def process_full_frame_( self, full_frame_, summary_D ):

        for chunk in full_frame_:
           summary_D['sample_summary'] = chunk
           self.mergeAndInsert( summary_D )
        
    def read_excel_file(self):
        # Load the workbook
        main_timer_ = time.time()
        workbook = openpyxl.load_workbook( self.file_path )
        #workbook = openpyxl.load_workbook( self.file_path, read_only=True )
        # Get the specified sheet in the workbook
        summary_D = dict()

        print( ' Time taken to open workbook->', time.time() - main_timer_)
        for sheet_obj in workbook:
            tt_ = time.time()
            self.sheet = sheet_obj
            sheet_name = self.sheet.title
            ## find all tables in the sheet
            #if 'Testing' not in self.sheet.title: continue

            print('Iterating over sheet->', self.sheet.title, self.sheet.max_row)

            all_tables_ = self.find_tables( self.sheet )
            print( 'ALL TABLES in the sheet->', sheet_name, all_tables_)
            print('TIMER: self.find_tables :: ', time.time() - tt_)
            
            for tblidx, tbl_ in enumerate( all_tables_ ):
                frame_, transposed_frame_ = '', ''
                print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')

                if tbl_['START_ROW'] is None or tbl_['END_ROW'] is None or tbl_['START_COL'] is None\
                        or tbl_['END_COL'] is None:
                            print('The tbl and sheet->', self.sheet.title,' no data!')

                try:
                    frame_, high_variance_cols_, col_names_ = self.returnSummary( tbl_ )

MODULE_VARIABLES-> Here is the list of module-level variables:

["None"]
PACKAGE_VARIABLES-> [{ 'time': 'time' },{ 'openpyxl': 'openpyxl' }]
METHODS-> [{ 'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_( self, full_frame_, summary_D ):', 'method_end': 'self.mergeAndInsert( summary_D )' },{ 'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self):', 'method_end': 'NA' },{ 'method_name': 'returnSummary', 'method_begin': 'def returnSummary( self, tbl_ ):', 'method_end': 'NA' },{ 'method_name': 'find_tables', 'method_begin': 'def find_tables( self, sheet ):', 'method_end': 'NA' },{ 'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA' }]
time post groq-> 282.6502718925476
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self, tbl ): ', 'method_end': 'return frame_, high_variance_cols_, list( set(hdr_col_names_) )', 'range': (312, 337)}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 76)}, {'method_name': 'createDBRec', 'method_begin': "def createDBRec( self, summary_D, mode='NORM' ):", 'method_end': 'return insertRec', 'range': (359, 383)}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA', 'range': (385, 76)}, {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet( self, tbl_, sheet_name ): ', 'method_end': 'NA', 'range': (396, 76)}] [{'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_( self, full_frame_, summary_D ):', 'method_end': 'self.mergeAndInsert( summary_D )'}, {'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self):', 'method_end': 'NA'}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary( self, tbl_ ):', 'method_end': 'NA'}, {'method_name': 'find_tables', 'method_begin': 'def find_tables( self, sheet ):', 'method_end': 'NA'}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA'}]
First occurence of  def process_full_frame_( self, full_frame_, summary_D ):  line # 438
First occurence of  self.mergeAndInsert( summary_D )  line # 442
First occurence of  def read_excel_file(self):  line # 444
First occurence of  NA  line # 76
First occurence of  def returnSummary( self, tbl_ ):  line # 312
First occurence of  NA  line # 76
First occurence of  NA  line # 76
First occurence of  def mergeAndInsert( self, summary_D ):  line # 385
First occurence of  NA  line # 76
Last method extracted-> {'method_name': 'returnSummary', 'method_begin': 'def returnSummary( self, tbl_ ):', 'method_end': 'NA', 'range': (312, 76)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 282.6586904525757
---------------------------------
CHUNK->                     print('TIMER: self.returnSummary :: ', time.time() - tt_)
                    full_frame_, is_full_frame_necessary_ = self.returnEntireSheet( tbl_, sheet_name )
                    ## find date range if available
                    summary_D['date_range'] = self.findDateRange( tbl_ )
                    summary_D['file_path'] = self.file_path
                    summary_D['sheet_name'] = sheet_name
                    summary_D['col_names_'] = col_names_
                    ## summarize hdr info
                    hdr_frame_ = self.findHeaderInfo( tbl_ )
                    print('TIMER: self.findHeaderInfo :: ', time.time() - tt_)

                    #summary_D['hdr_info'] = self.query_fn_.augmentHeaderInformation( hdr_frame_ )
                    summary_D['hdr_info'] = self.file_path.split('/')[-1] + ' ' + sheet_name + ' ' + \
                                            hdr_frame_ #+ ' ' + summary_D['hdr_info']

                    print('TIMER: self.findDateRange :: ', time.time() - tt_)

                    if summary_D['date_range'] == ( None, None ):
                        ## just add the timestamp of the file ..backup , BUT better than no time dimension
                        summary_D['date_range'] = \
                            datetime.datetime.fromtimestamp( os.path.getmtime(self.file_path) ).strftime('%B %d, %Y')

                    if is_full_frame_necessary_ == True:
                        self.process_full_frame_( full_frame_, summary_D )
                        print('All TEXT ..hence saving chunks!')
                        continue

                    summary_ = self.query_fn_.returnDocSummary( frame_, high_variance_cols_ )

                    print( tblidx,' :: ', tbl_, '::', '\n', frame_, '\n LLAMA3: ', summary_  )
                    print('TIMER: self.query_fn_.returnDocSummary :: ', time.time() - tt_)
                    time.sleep(1) ## groq APIs while testing this were timing out like crazy


MODULE_VARIABLES-> "['tt_', 'tbl_', 'sheet_name', 'col_names_', 'file_path', 'query_fn_']"
PACKAGE_VARIABLES-> [
    {"datetime": "datetime"},
    {"os": "os"},
    {"time": "time"}
]
METHODS-> [ ]
time post groq-> 320.7443127632141
EXISTING file_methods_ =  [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self, tbl ): ', 'method_end': 'return frame_, high_variance_cols_, list( set(hdr_col_names_) )', 'range': (312, 337)}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 76)}, {'method_name': 'createDBRec', 'method_begin': "def createDBRec( self, summary_D, mode='NORM' ):", 'method_end': 'return insertRec', 'range': (359, 383)}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA', 'range': (385, 76)}, {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet( self, tbl_, sheet_name ): ', 'method_end': 'NA', 'range': (396, 76)}, {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_( self, full_frame_, summary_D ):', 'method_end': 'self.mergeAndInsert( summary_D )', 'range': (438, 442)}, {'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self):', 'method_end': 'NA', 'range': (444, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary( self, tbl_ ):', 'method_end': 'NA', 'range': (312, 76)}] []
BACKUP CALL to "METHOD_ENDING"  [{'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self):', 'method_end': 'return None'}, {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet(self, tbl, sheet_name):', 'method_end': 'return (full_frame_, is_full_frame_necessary_)'}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange(self, tbl):', 'method_end': "return summary_D['date_range']"}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'return hdr_frame_'}, {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_(self, full_frame_, summary_D):', 'method_end': ''}, {'method_name': 'returnDocSummary', 'method_begin': 'def returnDocSummary(self, frame, high_variance_cols):', 'method_end': 'return summary_'}]
First occurence of  return None  line # 18
First occurence of  def returnEntireSheet(self, tbl, sheet_name):  line # 396
First occurence of  def findHeaderInfo(self, tbl):  line # 231
First occurence of  def process_full_frame_(self, full_frame_, summary_D):  line # 438
First occurence of    line # 0
Last method extracted-> {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_(self, full_frame_, summary_D):', 'method_end': '', 'range': (438, 0)}  Has no ending ..setting backtract to True
CHUNK_ENDS-> backtrack_ =  True
time post pprocess-> 333.7249574661255
---------------------------------
CHUNK->                     #print('Sending to LLM for summary->', summary_, '\n', summary_transposed_)
                    ## append file name, sheet name
                    print('Time taken for first 2 LLM calls->', time.time() - tt_)
                    summary_D['sample_summary'] = self.file_path.split('/')[-1] + ' ' + sheet_name + ' ' + summary_

                    print('Time Taken->', time.time() - tt_)
                    print('Time taken for last LLM calls->', time.time() - tt_)

                    #summary_D['pandas_dataframe'] = self.convertToPandas( tbl_ )
                    #print('Time taken for pandas calls->', time.time() - tt_)
                    ## now MERGE all the info and push into vector DB
                    self.mergeAndInsert( summary_D )
                    print('TIMER: self.mergeAndInsert :: ', time.time() - tt_)
                except:
                    print( 'EXCPN-> '+self.file_path + ' ' + sheet_name + ' ' + traceback.format_exc() )
                    continue

                self.masterInfo_[ sheet_name ] = summary_D

if __name__ == '__main__':
    files_ = os.listdir( './DATA/' )

    for file_ in files_:
        try:
            if 'Indexing Process' not in file_: continue

            get_meta_ = GenerateXLMetaInfo( './DATA/' + file_ )
            get_meta_.read_excel_file()
        except:
            print('EXCPN2-> File Loader FAIL = '+'./DATA/' + file_)
            print( traceback.format_exc() )
            continue

    '''

    get_meta_ = GenerateXLMetaInfo( './DATA/Time & Accuracy.xlsx' )
    get_meta_.read_excel_file()

    '''

MODULE_VARIABLES-> ["files_", "os"]
PACKAGE_VARIABLES-> [{"os": ""}, {"traceback": ""}]
METHODS-> Here is the output:

[{'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert(self, summary_D)', 'method_end': 'NA'}, 
 {'method_name': 'convertToPandas', 'method_begin': 'def convertToPandas(self, tbl_)', 'method_end': 'NA'}, 
 {'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self)', 'method_end': 'NA'}]
time post groq-> 368.32346057891846
No array returned by the model
CHUNK_ENDS-> backtrack_ =  None
time post pprocess-> 368.32349729537964
Going to SORT-> {'/datadrive/IKG/LLM_INTERFACE/SRC_DIR/basic_generateXLMetaData.py': [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 18)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 51)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 65)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row ,end_row ,start_col ,end_col ):', 'method_end': 'NA', 'range': (82, 76)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 119)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 130)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 151)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 229)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'NA', 'range': (231, 76)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary(self, tbl ): ', 'method_end': 'return frame_, high_variance_cols_, list( set(hdr_col_names_) )', 'range': (312, 337)}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 76)}, {'method_name': 'createDBRec', 'method_begin': "def createDBRec( self, summary_D, mode='NORM' ):", 'method_end': 'return insertRec', 'range': (359, 383)}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA', 'range': (385, 76)}, {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet( self, tbl_, sheet_name ): ', 'method_end': 'NA', 'range': (396, 76)}, {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_( self, full_frame_, summary_D ):', 'method_end': 'self.mergeAndInsert( summary_D )', 'range': (438, 442)}, {'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self):', 'method_end': 'NA', 'range': (444, 76)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary( self, tbl_ ):', 'method_end': 'NA', 'range': (312, 76)}, {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet(self, tbl, sheet_name):', 'method_end': 'return (full_frame_, is_full_frame_necessary_)', 'range': (396, None)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'return hdr_frame_', 'range': (231, None)}, {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_(self, full_frame_, summary_D):', 'method_end': '', 'range': (438, 0)}]}
ooooooooooooooooooooooooooooooooooooooooooo
extracted CONTENTS-> [] 
 {'/datadrive/IKG/LLM_INTERFACE/SRC_DIR/basic_generateXLMetaData.py': [{'numpy': 2}, {'np': 2}, {'pandas': 6}, {'pd': 6}, {'query_llama3_via_groq': 9}, {'llama3': 9}, {'query_gpt_via_groq': 10}, {'openai': 10}, {'sklearn.decomposition': 7}, {'PCA': 7}]} 
 [{'method_name': 'is_date', 'method_begin': 'def is_date( input_str):', 'method_end': 'return None', 'range': (14, 33)}, {'method_name': 'process', 'method_begin': 'def process( colNum, sheet, tbl ):', 'method_end': 'return ( False, None, None )', 'range': (33, 54)}, {'method_name': '__init__', 'method_begin': "def __init__(self, file_path, llm='LLAMA'): ", 'method_end': 'self.sklearn_pca_object_ = PCA()', 'range': (54, 82)}, {'method_name': 'find_bounds', 'method_begin': 'def find_bounds( self, sheet, max_row, max_col, start_row , end_row ,start_col ,end_col ): ', 'method_end': 'return start_row, end_row, start_col, end_col', 'range': (82, 121)}, {'method_name': 'is_hdr_row_format', 'method_begin': 'def is_hdr_row_format( self, tbl_bound, sheet ): ', 'method_end': 'return True', 'range': (121, 132)}, {'method_name': 'find_tables', 'method_begin': 'def find_tables(self, sheet): ', 'method_end': "table_bounds_.append( { 'START_ROW': start_row, 'END_ROW': end_row,\\ ", 'range': (132, 218)}, {'method_name': 'findDateRange', 'method_begin': 'def findDateRange( self, tbl ):', 'method_end': 'return (None, None)', 'range': (218, 231)}, {'method_name': 'findHeaderInfo', 'method_begin': 'def findHeaderInfo(self, tbl):', 'method_end': 'return hdr_frame_', 'range': (231, 253)}, {'method_name': 'findHighVarianceColumns', 'method_begin': 'def findHighVarianceColumns(self, start_hdr_row_, sheet, tbl ):', 'method_end': 'NA', 'range': (253, 312)}, {'method_name': 'returnSummary', 'method_begin': 'def returnSummary( self, tbl_ ):', 'method_end': 'NA', 'range': (312, 339)}, {'method_name': 'findHdrRow', 'method_begin': 'def findHdrRow( self, tbl ): ', 'method_end': 'NA', 'range': (339, 359)}, {'method_name': 'createDBRec', 'method_begin': "def createDBRec( self, summary_D, mode='NORM' ):", 'method_end': 'return insertRec', 'range': (359, 385)}, {'method_name': 'mergeAndInsert', 'method_begin': 'def mergeAndInsert( self, summary_D ):', 'method_end': 'NA', 'range': (385, 396)}, {'method_name': 'returnEntireSheet', 'method_begin': 'def returnEntireSheet(self, tbl, sheet_name):', 'method_end': 'return (full_frame_, is_full_frame_necessary_)', 'range': (396, 438)}, {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_(self, full_frame_, summary_D):', 'method_end': '', 'range': (438, 444)}, {'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self):', 'method_end': 'NA', 'range': (444, 76)}, {'method_name': 'process_full_frame_', 'method_begin': 'def process_full_frame_(self, full_frame_, summary_D):', 'method_end': '', 'range': (438, 444)}, {'method_name': 'read_excel_file', 'method_begin': 'def read_excel_file(self):', 'method_end': 'NA', 'range': (444, 76)}]
