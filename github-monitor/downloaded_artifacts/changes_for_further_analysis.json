[{"file": "LLM_INTERFACE/SRC_DIR/basic_generateXLMetaData.py", "old_start": 133, "old_length": 8, "new_start": 133, "new_length": 8, "old_code": ["        max_row = sheet.max_row if sheet.max_row is not None else self.default_max_row_\n", "        max_col = sheet.max_column if sheet.max_column is not None else self.default_max_col_\n", "-- a/LLM_INTERFACE/ast_utils.py\n"], "new_code": ["        max_row = sheet.max_row if sheet.max_row is not None else 20\n", "        max_col = sheet.max_column if sheet.max_column is not None else 30\n", "++ b/LLM_INTERFACE/ast_utils.py\n"], "method_class_nm_old": {"class_nm": "GenerateXLMetaInfo", "method_nm": "find_tables"}, "method_class_nm_new": {"class_nm": "GenerateXLMetaInfo", "method_nm": "find_tables"}}, {"file": "LLM_INTERFACE/ast_utils.py", "old_start": 13, "old_length": 6, "new_start": 13, "new_length": 13, "old_code": [], "new_code": ["    \n", "    def parse_ast_snippet( self, snippet_arr_):\n", "        local_snippet_ = snippet_arr_[:-1] # the last entry is always some thing like -- a/ ++ b/ \n", "        code_snippet_ = textwrap.dedent( ''.join( local_snippet_ ) )\n", "        parsed_ast = ast.parse( code_snippet_ )\n", "        # Parse the code into an AST\n", "        return parsed_ast\n"], "method_class_nm_old": {"class_nm": "CodeAnalyzer", "method_nm": "parse_ast"}, "method_class_nm_new": {"class_nm": "CodeAnalyzer", "method_nm": "parse_ast"}}, {"file": "LLM_INTERFACE/ast_utils.py", "old_start": 24, "old_length": 21, "new_start": 31, "new_length": 24, "old_code": ["        self.ast_linewise_deets_[ node.lineno ] = { 'Type':'Assignment', 'Targets': targets }\n", "        self.ast_linewise_deets_[ node.lineno ] = { 'Type':'If Statement', 'Targets': test_names , 'Ending': node.body[-1].lineno }\n", "        self.ast_linewise_deets_[ node.lineno ] = { 'Type':'For loop',  'Targets': iter_names, 'Ending': node.body[-1].lineno }\n", "-- a/LLM_INTERFACE/chunking_utils.py\n"], "new_code": ["        self.ast_linewise_deets_[ node.lineno ] = { 'Type':'Assignment', 'Targets': targets,\\\n", "                                                    'Ending': 'NA', 'Values': value_names }\n", "        self.ast_linewise_deets_[ node.lineno ] = { 'Type':'If Statement', 'Targets': test_names , \\\n", "                                                     'Ending': node.body[-1].lineno, 'Values': 'NA' }\n", "        self.ast_linewise_deets_[ node.lineno ] = { 'Type':'For loop', 'Targets': iter_names, \\\n", "                                                    'Ending': node.body[-1].lineno, 'Values': 'NA' }\n", "++ b/LLM_INTERFACE/chunking_utils.py\n"], "method_class_nm_old": {"class_nm": "CodeAnalyzer", "method_nm": "gc"}, "method_class_nm_new": {"class_nm": "CodeAnalyzer", "method_nm": "visit_Assign"}}, {"file": "LLM_INTERFACE/chunking_utils.py", "old_start": 7, "old_length": 6, "new_start": 7, "new_length": 7, "old_code": [], "new_code": ["        print('FINDING RANGE->', ref_file_, input_file_)\n"], "method_class_nm_old": {"class_nm": null, "method_nm": "findRange"}, "method_class_nm_new": {"class_nm": null, "method_nm": "findRange"}}, {"file": "LLM_INTERFACE/chunking_utils.py", "old_start": 14, "old_length": 7, "new_start": 15, "new_length": 88, "old_code": ["def createChunkInChangeFile( method_name, file_name, summary_of_changes ):\n"], "new_code": ["def cmpOldNew( old_code_vars_, new_code_vars_, target_dict_ ):\n", "    '''\n", "    so if the variables used in old code are \"a\" and \"B\" and in the new \"a\" is deleted a new one \"C\"\n", "    is being used , we simply need to find how many lines actually use these variables and its assignees\n", "    no point sending more than this context to the LLM ..capisce ?\n", "    '''\n", "    min_ln_, max_ln_ = 10000, -1\n", "\n", "    for _ , assignment_deets in old_code_vars_.items():\n", "        tgt_of_interest_ = assignment_deets['Targets'][0]\n", "\n", "        if tgt_of_interest_ in target_dict_ and target_dict_[tgt_of_interest_]['MAX'] is not None:\n", "            idx_ = target_dict_[tgt_of_interest_]['MAX']\n", "\n", "            while idx_ < len( target_dict_ ) - 1:\n", "                neo_tgt_ = target_dict_[tgt_of_interest_]['MAX_LN_TGT']\n", "\n", "                if neo_tgt_ in target_dict_ and target_dict_[neo_tgt_]['MAX'] is not None:\n", "                    idx_ = target_dict_[neo_tgt_]['MAX']\n", "                    if target_dict_[neo_tgt_]['MIN'] < min_ln_ : min_ln_ = target_dict_[neo_tgt_]['MIN'] \n", "                    if target_dict_[neo_tgt_]['MAX'] > max_ln_ : max_ln_ = target_dict_[neo_tgt_]['MAX']\n", "                else:\n", "                    idx_ += 1\n", "\n", "    for _ , assignment_deets in new_code_vars_.items():\n", "        tgt_of_interest_ = assignment_deets['Targets'][0]\n", "\n", "        if tgt_of_interest_ in target_dict_ and target_dict_[tgt_of_interest_]['MAX'] is not None:\n", "            idx_ = target_dict_[tgt_of_interest_]['MAX']\n", "\n", "            while idx_ < len( target_dict_ ) - 1:\n", "                neo_tgt_ = target_dict_[tgt_of_interest_]['MAX_LN_TGT']\n", "\n", "                if neo_tgt_ in target_dict_ and target_dict_[neo_tgt_]['MAX'] is not None:\n", "                    idx_ = target_dict_[neo_tgt_]['MAX']\n", "                    if target_dict_[neo_tgt_]['MIN'] < min_ln_ : min_ln_ = target_dict_[neo_tgt_]['MIN'] \n", "                    if target_dict_[neo_tgt_]['MAX'] > max_ln_ : max_ln_ = target_dict_[neo_tgt_]['MAX']\n", "                else:\n", "                    idx_ += 1\n", "                    \n", "    return min_ln_, max_ln_\n", "\n", "def getSphereOfInfluence( ast_details_, changed_code_, old_code_ ):\n", "    # parse_ast_snippet\n", "    ast_old_, ast_new_ = CodeAnalyzer(), CodeAnalyzer()\n", "    old_code_ast_, new_code_ast_ = ast_old_.parse_ast_snippet( old_code_ ), \\\n", "                                   ast_new_.parse_ast_snippet( changed_code_ )\n", "    \n", "    ast_old_.visit( old_code_ast_ )\n", "    ast_new_.visit( new_code_ast_ )\n", "\n", "    old_code_vars_, new_code_vars_ = ast_old_.ast_linewise_deets_, ast_new_.ast_linewise_deets_\n", "    ## go through ast_details_ and find the begin and ending reference of the variable ( direct and indirect )\n", "    target_dict_ = dict()\n", "    for ln_no, line_ast_ in ast_details_.items():\n", "\n", "        for eval_tgt_ in line_ast_['Targets']:\n", "            max_ln_, min_line_ = -1, 10000\n", "\n", "            for ln_no, line_ast_ in ast_details_.items():\n", "\n", "                if eval_tgt_ in line_ast_['Values'] and max_ln_ < ln_no:\n", "                    max_ln_ = ln_no\n", "\n", "                if eval_tgt_ in line_ast_['Values'] and min_line_ > ln_no:\n", "                    min_line_ = ln_no\n", "\n", "            print('Furthest assignment of ',eval_tgt_,' is ', max_ln_, max_val_)\n", "\n", "            target_dict_[ eval_tgt_ ] = { 'MIN': min_line_ if min_line_ != 10000 else None ,\\\n", "                                          'MAX': max_ln_ if max_ln_ != -1 else None,\\\n", "                                     'MAX_LN_TGT': ast_details_[max_ln_]['Targets'][0] if max_ln_ != -1 else None }\n", "\n", "    ## the above will result in a DS like so\n", "    ## key-> target value -> nearest & furthest USAGE of \"target\" as a VALUE .. so that we can follow the bread\n", "    ## crumbs to the last indirect assignment of the target\n", "    ast_old_.gc()\n", "    ast_new_.gc()\n", "\n", "    return cmpOldNew( old_code_vars_, new_code_vars_, target_dict_ )\n", "\n", "def createChunkInChangeFile( summary_of_changes ):\n"], "method_class_nm_old": {"class_nm": null, "method_nm": "findRange"}, "method_class_nm_new": {"class_nm": null, "method_nm": "findRange"}}, {"file": "LLM_INTERFACE/chunking_utils.py", "old_start": 33, "old_length": 11, "new_start": 115, "new_length": 12, "old_code": ["\n", "        file_nm_, method_nm_, changed_code_, old_code_ = changeD['file'], changeD['method_nm'], \\\n"], "new_code": ["    chunks_for_analysis_ = []\n", "    \n", "        file_nm_, method_nm_, changed_code_, old_code_ = changeD['file'], changeD[\"method_class_nm_old\"]['method_nm'], \\\n"], "method_class_nm_old": {"class_nm": null, "method_nm": "cmpOldNew"}, "method_class_nm_new": {"class_nm": null, "method_nm": "createChunkInChangeFile"}}, {"file": "LLM_INTERFACE/chunking_utils.py", "old_start": 49, "old_length": 12, "new_start": 132, "new_length": 21, "old_code": ["        with open( file_name, 'r' ) as fp:\n", "            file_contents_ = fp.readlines()\n", "        method_specific_lines_ = file_contents_[ begin_ln_: end_ln_ ]\n", "        chunk_range_ = findChunkRange( method_specific_lines_, ast_details_, \n"], "new_code": ["        code_review_range_ = getSphereOfInfluence( ast_details_, changed_code_, old_code_ )\n", "\n", "        with open( file_nm_, 'r' ) as fp:\n", "            tmp_contents_ = fp.readlines()\n", "\n", "        if code_review_range_[0] == 10000 or code_review_range_[1] == -1:\n", "            print('Sending the entire code of <', method_nm_,'> for review')\n", "        else:\n", "            print('Found contextual subtext for <', method_nm_,'>')\n", "            begin_ln_, end_ln_ = code_review_range_\n", "\n", "        chunks_for_analysis_.append( changeD.update( { 'method_context': tmp_contents_[ begin_ln_: end_ln_ ] } ) )\n", "    ast_utils_.gc()\n"], "method_class_nm_old": {"class_nm": null, "method_nm": "cmpOldNew"}, "method_class_nm_new": {"class_nm": null, "method_nm": "createChunkInChangeFile"}}, {"file": "LLM_INTERFACE/chunking_utils.py", "old_start": 63, "old_length": 9, "new_start": 155, "new_length": 11, "old_code": ["def checkIfLegitVariable( method_name, file_name, var_name_ ):\n", "    '''\n", "    whilst calling createChunkInChangeFile, the LLM would return a bunch of variables ..need to ensure these\n", "    varuables are indeed present in the context\n", "    '''\n"], "new_code": ["    return None\n", "if __name__ == '__main__':\n", "    import json\n", "    with open( '../github-monitor/downloaded_artifacts/changes_for_further_analysis.json', 'r' ) as fp:\n", "        js_ = json.load( fp )\n", "\n", "    createChunkInChangeFile( js_ )\n"], "method_class_nm_old": {"class_nm": null, "method_nm": "getSphereOfInfluence"}, "method_class_nm_new": {"class_nm": null, "method_nm": "createChunkInDownStreamFile"}}]